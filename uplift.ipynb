{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Uplift Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, please import the dataframe from the two first models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a treatment column to the dataframe\n",
    "# Randomly assign a 0 or 1 to each row. 1 for treatment, 0 for control\n",
    "df['treatment'] = np.random.randint(2, size=len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.treatment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the treatment's correlation to repeat purchases:\n",
    "def correlation_treatment(df:pd.DataFrame):\n",
    "    \"\"\"Function to calculate the treatment's correlation\n",
    "    \"\"\"\n",
    "    correlation = df[['treatment','REPEATER']].corr(method ='pearson') \n",
    "    return(pd.DataFrame(round(correlation.loc['REPEATER'] * 100,2)))\n",
    "\n",
    "correlation_treatment(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_target_class(df:pd.DataFrame):\n",
    "    \"\"\"Function for declare the target class\n",
    "    \"\"\"\n",
    "    # Control Non Repeaters (CN) : 0\n",
    "    df['target_class'] = 0 \n",
    "    # Control Repeaters (CR) : 1\n",
    "    df.loc[(df.treatment == 0) & (df.REPEATER == 0),'target_class'] = 1 \n",
    "    # Treatment Non Repeaters (TN) : 2\n",
    "    df.loc[(df.treatment == 1) & (df.REPEATER == 1),'target_class'] = 2 \n",
    "    # Treatment Repeaters (TR) : 3\n",
    "    df.loc[(df.treatment == 1) & (df.REPEATER == 0),'target_class'] = 3 \n",
    "    return df\n",
    "\n",
    "df = declare_target_class(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_model:pd.DataFrame):\n",
    "    \"\"\"Split data into training data and testing data\n",
    "    \"\"\"\n",
    "    X = df_model.drop(['REPEATER', 'CLTV','target_class'],axis=1)\n",
    "    y = df_model.REPEATER\n",
    "    z = df_model.target_class\n",
    "    X_train, X_test, \\\n",
    "    y_train, y_test, \\\n",
    "    z_train, z_test = train_test_split(X,\n",
    "                                       y,\n",
    "                                       z,\n",
    "                                       test_size=0.3,\n",
    "                                       random_state=42,\n",
    "                                       stratify=df_model['treatment'])\n",
    "    return X_train,X_test, y_train, y_test, z_train, z_test\n",
    "\n",
    "\n",
    "def machine_learning(X_train:pd.DataFrame,\n",
    "                     X_test:pd.DataFrame,\n",
    "                     y_train:pd.DataFrame,\n",
    "                     y_test:pd.DataFrame,\n",
    "                     z_train:pd.DataFrame,\n",
    "                     z_test:pd.DataFrame):\n",
    "    \"\"\"Machine learning process consists of \n",
    "    data training, and data testing process (i.e. prediction) with XGBoost (XGB) Algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare a new DataFrame\n",
    "    prediction_results = pd.DataFrame(X_test).copy()\n",
    "    \n",
    "    \n",
    "    # train the ETP model\n",
    "    model_tp \\\n",
    "    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), y_train)  \n",
    "    # prediction Process for ETP model \n",
    "    prediction_tp \\\n",
    "    = model_tp.predict(X_test.drop('treatment',axis=1))\n",
    "    probability__tp \\\n",
    "    = model_tp.predict_proba(X_test.drop('treatment', axis=1))\n",
    "    prediction_results['prediction_REPEATER'] = prediction_tp\n",
    "    prediction_results['proba_REPEATER'] = probability__tp[:,1]\n",
    "    \n",
    "    \n",
    "    # train the ETU model\n",
    "    model_etu \\\n",
    "    = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), z_train)\n",
    "    # prediction Process for ETU model \n",
    "    prediction_etu \\\n",
    "    = model_etu.predict(X_test.drop('treatment', axis=1))\n",
    "    probability__etu \\\n",
    "    = model_etu.predict_proba(X_test.drop('treatment', axis=1))\n",
    "    prediction_results['prediction_target_class'] = prediction_etu\n",
    "    prediction_results['proba_CN'] = probability__etu[:,0] \n",
    "    prediction_results['proba_CR'] = probability__etu[:,1] \n",
    "    prediction_results['proba_TN'] = probability__etu[:,2] \n",
    "    prediction_results['proba_TR'] = probability__etu[:,3]\n",
    "    prediction_results['score_etu'] = prediction_results.eval('\\\n",
    "    proba_CN/(proba_CN+proba_CR) \\\n",
    "    + proba_TR/(proba_TN+proba_TR) \\\n",
    "    - proba_TN/(proba_TN+proba_TR) \\\n",
    "    - proba_CR/(proba_CN+proba_CR)')  \n",
    "    # add the REPEATER and target class into dataframe as validation data\n",
    "    prediction_results['REPEATER'] = y_test\n",
    "    prediction_results['target_class'] = z_test\n",
    "    return prediction_results\n",
    "\n",
    "\n",
    "def predict(df_model:pd.DataFrame):\n",
    "    \"\"\"Combining data split and machine learning process with XGB\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test, z_train, z_test = split_data(df_model)\n",
    "    prediction_results = machine_learning(X_train,\n",
    "                                          X_test,\n",
    "                                          y_train,\n",
    "                                          y_test,\n",
    "                                          z_train,\n",
    "                                          z_test)\n",
    "    print(\"✔️Prediction succeeded\")\n",
    "    return prediction_results\n",
    "\n",
    "# Machine Learning Modelling Process\n",
    "print(\"Predicting dataset 1 ...\")\n",
    "prediction_results_1 = predict(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_evaluation(df:pd.DataFrame):\n",
    "    \"\"\"Confusion matrix evaluation\n",
    "    \"\"\"  \n",
    "    print(\"===================================\")\n",
    "    print(\"1. ETP's confusion matrix result:\")\n",
    "    confusion_etp = confusion_matrix(df['REPEATER'], df['prediction_REPEATER'])\n",
    "    df_confusion_etp = pd.DataFrame(confusion_etp, columns = ['Predicted True','Predicted False'], index = ['Actual True','Actual False'])\n",
    "    print(df_confusion_etp)\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    print(\"2. ETU's confusion matrix result:\")   \n",
    "    confusion_etu = multilabel_confusion_matrix(df['target_class'], df['prediction_target_class'])\n",
    "    print(\"a. CN's confusion matrix:\")  \n",
    "    df_cn = pd.DataFrame(confusion_etu[0], columns = ['Predicted True','Predicted False'], index = ['Actual True','Actual False'])\n",
    "    print(df_cn)\n",
    "    print(\"b. CR's confusion matrix:\") \n",
    "    df_cr = pd.DataFrame(confusion_etu[1], columns = ['Predicted True','Predicted False'], index = ['Actual True','Actual False'])\n",
    "    print(df_cr) \n",
    "    print(\"c. TN's confusion matrix:\")\n",
    "    df_tn = pd.DataFrame(confusion_etu[2], columns = ['Predicted True','Predicted False'], index = ['Actual True','Actual False'])\n",
    "    print(df_tn) \n",
    "    print(\"d. TR's confusion matrix:\") \n",
    "    df_tr = pd.DataFrame(confusion_etu[3], columns = ['Predicted True','Predicted False'], index = ['Actual True','Actual False'])\n",
    "    print(df_tr)\n",
    "    \n",
    "    print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Evaluation\n",
    "print(\"✔️Dataset 1\")\n",
    "cm_evaluation(prediction_results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_evaluation(df:pd.DataFrame):\n",
    "    \"\"\"Accuracy evaluation\n",
    "    \"\"\"\n",
    "    akurasi_cp = accuracy_score(df['REPEATER'],\n",
    "                                df['prediction_REPEATER'])\n",
    "    print('✔️ETP model accuracy: %.2f%%' % (akurasi_cp * 100.0))\n",
    "    \n",
    "    \n",
    "    akurasi_uplift = accuracy_score(df['target_class'],\n",
    "                                    df['prediction_target_class'])\n",
    "    print('✔️ETU model accuracy: %.2f%%' % (akurasi_uplift * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Evaluation Process.\n",
    "print(\"Dataset 1\")\n",
    "accuracy_evaluation(prediction_results_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the prescriptive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_data(df:pd.DataFrame):\n",
    "    \"\"\"Function to sort data\n",
    "    \"\"\"\n",
    "    # Set up new DataFrames for ETP model and ETU model\n",
    "    df_c = pd.DataFrame({'n':[], 'target_class':[]})\n",
    "    df_u = df_c.copy()\n",
    "    df_c['target_class'] = df['target_class']\n",
    "    df_u['target_class'] = df['target_class']\n",
    "    \n",
    "    \n",
    "    # Add quantiles\n",
    "    df_c['n'] = df.proba_REPEATER.rank(pct=True, ascending=False)\n",
    "    df_u['n'] = df.score_etu.rank(pct=True, ascending=False)\n",
    "    df_c['score'] = df['proba_REPEATER']\n",
    "    df_u['score'] = df['score_etu']\n",
    "    \n",
    "    \n",
    "    # Ranking the data by deciles\n",
    "    df_c = df_c.sort_values(by='n').reset_index(drop=True)\n",
    "    df_u = df_u.sort_values(by='n').reset_index(drop=True)\n",
    "    df_c['model'], df_u['model'] = 'CP', 'Uplift'\n",
    "    return df_c, df_u\n",
    "\n",
    "\n",
    "def calculating_qini(df:pd.DataFrame):\n",
    "    \"\"\"Function to measure the Qini value\n",
    "    \"\"\"\n",
    "    # Calculate the C, T, CR, and TR\n",
    "    C, T = sum(df['target_class'] <= 1), sum(df['target_class'] >= 2)\n",
    "    df['cr'] = 0\n",
    "    df['tr'] = 0\n",
    "    df.loc[df.target_class  == 1,'cr'] = 1\n",
    "    df.loc[df.target_class  == 3,'tr'] = 1\n",
    "    df['cr/c'] = df.cr.cumsum() / C\n",
    "    df['tr/t'] = df.tr.cumsum() / T\n",
    "    \n",
    "\n",
    "    # Calculate & add the qini value into the Dataframe\n",
    "    df['uplift'] = df['tr/t'] - df['cr/c']\n",
    "    df['random'] = df['n'] * df['uplift'].iloc[-1]\n",
    "    qini_coef= df['uplift'].sum(skipna = True) - df['random'].sum(skipna = True)\n",
    "\n",
    "    # Print the Qini coefficient\n",
    "    print('✔️Qini coefficient = {} {}'.format(round(qini_coef, 2), '%'))\n",
    "    \n",
    "    # Add q0 into the Dataframe\n",
    "    q0 = pd.DataFrame({'n':0, 'uplift':0, 'target_class': None}, index =[0])\n",
    "    qini = pd.concat([q0, df]).reset_index(drop = True)\n",
    "    return qini\n",
    "\n",
    "def merging_data(df_c:pd.DataFrame, df_u:pd.DataFrame):\n",
    "    \"\"\"Function to add the 'Model' column and merge the dataframe into one\n",
    "    \"\"\"\n",
    "    df_u['model'] = 'ETU'\n",
    "    df_c['model'] = 'ETP'\n",
    "    df = pd.concat([df_u, df_c]).sort_values(by='n').reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_qini(df:pd.DataFrame):\n",
    "    \"\"\"Function to plot the qini curve\n",
    "    \"\"\"\n",
    "    print('\\nPlotting the qini curve...')\n",
    "    \n",
    "    # Define the data that will be plotted\n",
    "    order = ['ETU','ETP']\n",
    "    ax = sns.lineplot(x='n', y=df.uplift, hue='model', data=df,\n",
    "                      style='model', palette=['red','deepskyblue'],\n",
    "                      style_order=order, hue_order = order)\n",
    "    \n",
    "    # Additional plot display settings\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.xlabel('Proportion targeted',fontsize=30)\n",
    "    plt.ylabel('Uplift',fontsize=30)\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.subplots_adjust(top=1)\n",
    "    plt.legend(fontsize=30)\n",
    "    ax.tick_params(labelsize=24)\n",
    "    ax.legend(handles=handles[1:], labels=labels[1:])\n",
    "    ax.plot([0,1], [0,df.loc[len(df) - 1,'uplift']],'--', color='grey')\n",
    "    print('✔️Successfully plot the qini curve')\n",
    "    return ax\n",
    "\n",
    "def evaluation_qini(prediction_results:pd.DataFrame):\n",
    "    \"\"\"Function to combine all qini evaluation processes\n",
    "    \"\"\"\n",
    "    df_c, df_u = sorting_data(prediction_results)\n",
    "    print('ETP model (previous model):')\n",
    "    qini_c = calculating_qini(df_c)\n",
    "    print('\\nETU model (our proposed model):')\n",
    "    qini_u = calculating_qini(df_u)\n",
    "    qini = merging_data(qini_c, qini_u)\n",
    "    ax = plot_qini(qini)\n",
    "    return ax, qini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qini evaluation results for DataSet 1 with negative treatment correlation\n",
    "ax, qini_1 = evaluation_qini(prediction_results_1)\n",
    "plt.title('Qini Curve - Dataset 1',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process to inverse treatment's parameter\n",
    "# Thus also inverse the treatment's correlation from negative to positive\n",
    "df.treatment = df.treatment.replace({0: 1, 1: 0})\n",
    "\n",
    "# Recalculate the treatment correlation\n",
    "print(\"✔️Treatment correlation in dataset 1 (inverted):\", correlation_treatment(df).iloc[0,0])\n",
    "\n",
    "# Add the target class feature to all three datasets\n",
    "df_inverse = declare_target_class(df)\n",
    "\n",
    "# Do the prediction process once more time\n",
    "prediction_results_inverse_1 = predict(df_inverse)\n",
    "\n",
    "# Qini evaluation results for DataSet 1 with positive treatment correlation\n",
    "ax, qini_inverse_1 = evaluation_qini(prediction_results_inverse_1)\n",
    "plt.title('Qini Curve - Dataset 1',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process to inverse treatment's parameter\n",
    "# Thus also inverse the treatment's correlation from negative to positive\n",
    "df.treatment = df.treatment.replace({0: 1, 1: 0})\n",
    "\n",
    "# Recalculate the treatment correlation\n",
    "print(\"✔️Treatment correlation in dataset 1 (inverted):\", correlation_treatment(df).iloc[0,0])\n",
    "\n",
    "# Add the target class feature to all three datasets\n",
    "df_inverse = declare_target_class(df)\n",
    "\n",
    "# Do the prediction process once more time\n",
    "prediction_results_inverse_1 = predict(df_inverse)\n",
    "\n",
    "# Qini evaluation results for DataSet 1 with positive treatment correlation\n",
    "ax, qini_inverse_1 = evaluation_qini(prediction_results_inverse_1)\n",
    "plt.title('Qini Curve - Dataset 1',fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
